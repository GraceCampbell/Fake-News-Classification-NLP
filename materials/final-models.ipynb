{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from tokenizer import token_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'Grace'}\n",
    "\n",
    "def get_posts():\n",
    "    onion_posts = []\n",
    "    after = None\n",
    "    for i in range(40):\n",
    "        if after == None:\n",
    "            params = {}\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        url = 'https://www.reddit.com/r/theonion.json'\n",
    "        res = requests.get(url, params=params, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            the_json = res.json()\n",
    "            onion_posts.extend(the_json['data']['children'])\n",
    "            after = the_json['data']['after']\n",
    "        else:\n",
    "            print(res.status_code)\n",
    "            break\n",
    "        time.sleep(2)\n",
    "\n",
    "    titles = []\n",
    "    for i in range(len(onion_posts)):\n",
    "        titles.append(onion_posts[i]['data']['title'])\n",
    "\n",
    "    onion_titles = list((set(titles)))\n",
    "\n",
    "    news_posts = []\n",
    "    after = None\n",
    "    for i in range(40):\n",
    "        if after == None:\n",
    "            params = {}\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        url = 'https://www.reddit.com/r/worldnews.json'\n",
    "        res = requests.get(url, params=params, headers=headers)\n",
    "        if res.status_code == 200:\n",
    "            the_json = res.json()\n",
    "            news_posts.extend(the_json['data']['children'])\n",
    "            after = the_json['data']['after']\n",
    "        else:\n",
    "            print(res.status_code)\n",
    "            break\n",
    "        time.sleep(2)\n",
    "\n",
    "    titles = []\n",
    "    for i in range(len(news_posts)):\n",
    "        titles.append(news_posts[i]['data']['title'])\n",
    "\n",
    "    news_titles = list(set(titles))\n",
    "\n",
    "    onion = pd.DataFrame(onion_titles)\n",
    "    onion['is_onion'] = 1\n",
    "\n",
    "    news = pd.DataFrame(news_titles)\n",
    "    news['is_onion'] = 0\n",
    "\n",
    "    titles = news.append(onion, ignore_index=True)\n",
    "    titles.rename({0: 'title'}, axis=1, inplace=True)\n",
    "    \n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes(X, y):\n",
    "    df = pd.read_csv('./materials/titles.csv')\n",
    "\n",
    "    X_og = df['title']\n",
    "    y_og = df['is_onion']\n",
    "    \n",
    "    cvec = CountVectorizer(tokenizer=token_func, max_features=X_og.shape[0], min_df=1, max_df=0.9)\n",
    "    cvec.fit(X_og)\n",
    "    \n",
    "    X_og_cvec = pd.DataFrame(cvec.transform(X_og).todense(), columns=cvec.get_feature_names())\n",
    "    X_cvec    = pd.DataFrame(cvec.transform(X).todense(), columns=cvec.get_feature_names())\n",
    "    \n",
    "    mnb = MultinomialNB(alpha=1)\n",
    "    mnb.fit(X_og_cvec, y)\n",
    "    print('Accuracy score: {mnb.score(X_cvec, y)}')\n",
    "    \n",
    "    y_pred = mnb.predict(X_cvec)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    print(f'Sensitivity: {tp/(tp+fn)}')\n",
    "    print(f'Specificity: {tn/(tn+fp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(X, y):\n",
    "    df = pd.read_csv('./materials/titles.csv')\n",
    "\n",
    "    X_og = df['title']\n",
    "    y_og = df['is_onion']\n",
    "    \n",
    "    tvec = TfidfVectorizer(tokenizer=token_func, max_features=X_og.shape[0], min_df=1, max_df=0.9)\n",
    "    tvec.fit(X_og)\n",
    "    \n",
    "    X_og_tvec = pd.DataFrame(cvec.transform(X_og).todense(), columns=tvec.get_feature_names())\n",
    "    X_tvec    = pd.DataFrame(cvec.transform(X).todense(), columns=tvec.get_feature_names())\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=15, weights='distance')\n",
    "    knn.fit(X_og_tvec, y)\n",
    "    print('Accuracy score: {knn.score(X_tvec, y)}')\n",
    "    \n",
    "    y_pred = knn.predict(X_tvec)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    print(f'Sensitivity: {tp/(tp+fn)}')\n",
    "    print(f'Specificity: {tn/(tn+fp)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc(X, y):\n",
    "    df = pd.read_csv('./materials/titles.csv')\n",
    "\n",
    "    X_og = df['title']\n",
    "    y_og = df['is_onion']\n",
    "    \n",
    "    tvec = TfidfVectorizer(tokenizer=token_func, max_features=X_og.shape[0], min_df=2, max_df=0.9)\n",
    "    tvec.fit(X_og)\n",
    "    \n",
    "    X_og_tvec = pd.DataFrame(cvec.transform(X_og).todense(), columns=tvec.get_feature_names())\n",
    "    X_tvec    = pd.DataFrame(cvec.transform(X).todense(), columns=tvec.get_feature_names())\n",
    "    \n",
    "    svc = SVC(kernel='rbf', C=10)\n",
    "    svc.fit(X_og_tvec, y)\n",
    "    print('Accuracy score: {svc.score(X_tvec, y)}')\n",
    "    \n",
    "    y_pred = svc.predict(X_tvec)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "\n",
    "    print(f'Sensitivity: {tp/(tp+fn)}')\n",
    "    print(f'Specificity: {tn/(tn+fp)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
